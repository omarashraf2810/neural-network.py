import numpy as np
import random
import math

# Define activation function (Sigmoid) and its derivative
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

class Neuron:
    def __init__(self, bias):
        self.bias = bias
        self.weights = []
    
    def calculate_output(self, inputs):
        self.inputs = inputs
        self.output = sigmoid(self.calculate_total_net_input())
        return self.output
    
    def calculate_total_net_input(self):
        return sum(self.inputs[i] * self.weights[i] for i in range(len(self.inputs))) + self.bias
    
    def calculate_pd_error_wrt_total_net_input(self, target_output):
        return (self.output - target_output) * sigmoid_derivative(self.output)

class NeuronLayer:
    def __init__(self, num_neurons, bias):
        self.bias = bias
        self.neurons = [Neuron(self.bias) for _ in range(num_neurons)]
    
    def feed_forward(self, inputs):
        return [neuron.calculate_output(inputs) for neuron in self.neurons]

class NeuralNetwork:
    LEARNING_RATE = 0.5
    
    def __init__(self, num_inputs, num_hidden, num_outputs, hidden_layer_weights=None, hidden_layer_bias=None, output_layer_weights=None, output_layer_bias=None):
        self.num_inputs = num_inputs
        self.hidden_layer = NeuronLayer(num_hidden, hidden_layer_bias)
        self.output_layer = NeuronLayer(num_outputs, output_layer_bias)
        self.init_weights(hidden_layer_weights, output_layer_weights)
    
    def init_weights(self, hidden_layer_weights, output_layer_weights):
        weight_num = 0
        for h in range(len(self.hidden_layer.neurons)):
            for i in range(self.num_inputs):
                self.hidden_layer.neurons[h].weights.append(hidden_layer_weights[weight_num] if hidden_layer_weights else random.random())
                weight_num += 1
        
        weight_num = 0
        for o in range(len(self.output_layer.neurons)):
            for h in range(len(self.hidden_layer.neurons)):
                self.output_layer.neurons[o].weights.append(output_layer_weights[weight_num] if output_layer_weights else random.random())
                weight_num += 1
    
    def feed_forward(self, inputs):
        hidden_layer_outputs = self.hidden_layer.feed_forward(inputs)
        return self.output_layer.feed_forward(hidden_layer_outputs)
    
    def train(self, training_inputs, training_outputs):
        self.feed_forward(training_inputs)
        pd_errors_wrt_output_neuron_total_net_input = [
            self.output_layer.neurons[o].calculate_pd_error_wrt_total_net_input(training_outputs[o])
            for o in range(len(self.output_layer.neurons))
        ]
        
        pd_errors_wrt_hidden_neuron_total_net_input = []
        for h in range(len(self.hidden_layer.neurons)):
            d_error_wrt_hidden_neuron_output = sum(
                pd_errors_wrt_output_neuron_total_net_input[o] * self.output_layer.neurons[o].weights[h]
                for o in range(len(self.output_layer.neurons))
            )
            pd_errors_wrt_hidden_neuron_total_net_input.append(
                d_error_wrt_hidden_neuron_output * sigmoid_derivative(self.hidden_layer.neurons[h].output)
            )
        
        for o in range(len(self.output_layer.neurons)):
            for w_ho in range(len(self.output_layer.neurons[o].weights)):
                self.output_layer.neurons[o].weights[w_ho] -= self.LEARNING_RATE * pd_errors_wrt_output_neuron_total_net_input[o] * self.hidden_layer.neurons[w_ho].output
        
        for h in range(len(self.hidden_layer.neurons)):
            for w_ih in range(len(self.hidden_layer.neurons[h].weights)):
                self.hidden_layer.neurons[h].weights[w_ih] -= self.LEARNING_RATE * pd_errors_wrt_hidden_neuron_total_net_input[h] * training_inputs[w_ih]
    
    def calculate_total_error(self, training_sets):
        total_error = sum(
            0.5 * (training_outputs[o] - self.output_layer.neurons[o].output) ** 2
            for training_inputs, training_outputs in training_sets
            for o in range(len(training_outputs))
        )
        return total_error

nn = NeuralNetwork(2, 2, 2, hidden_layer_weights=[0.15, 0.2, 0.25, 0.3], hidden_layer_bias=0.35, output_layer_weights=[0.4, 0.45, 0.5, 0.55], output_layer_bias=0.6)
for i in range(10000):
    nn.train([0.05, 0.1], [0.01, 0.99])
    print(i, round(nn.calculate_total_error([[[0.05, 0.1], [0.01, 0.99]]]), 9))
